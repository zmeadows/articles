\documentclass[11pt]{article}
\renewcommand{\baselinestretch}{1.05}
\usepackage{amsmath,amsthm,verbatim,amssymb,amsfonts,amscd, graphicx}
\usepackage{graphics}
\topmargin0.0cm
\headheight0.0cm
\headsep0.0cm
\oddsidemargin0.0cm
\textheight23.0cm
\textwidth16.5cm
\footskip1.0cm
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem*{surfacecor}{Corollary 1}
\newtheorem{conjecture}{Conjecture}
\newtheorem{question}{Question}
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\renewcommand{\vec}[1]{\mathbf{#1}} % make vectors bold

\setlength\parindent{0pt}

\usepackage{hyperref}
\hypersetup{
    pdftex,
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=blue,
    urlcolor=red
}

\usepackage{xcolor}
\newcommand{\highlight}[1]{%
  \colorbox{yellow!50}{$\displaystyle#1$}}

\newcount\colveccount
\newcommand*\colvec[1]{
        \global\colveccount#1
        \begin{pmatrix}
        \colvecnext
}
\def\colvecnext#1{
        #1
        \global\advance\colveccount-1
        \ifnum\colveccount>0
                \\
                \expandafter\colvecnext
        \else
                \end{pmatrix}
        \fi
}

\begin{document}

\title{Green's Functions}
\author{Zachary A. Meadows \\ \textit{University of Massachusetts Amherst}}
\maketitle
\tableofcontents

\section{Introduction}

Green's functions induce more confusion in the first few semesters of physics grad school than perhaps any other mathematical topic. The wide variety of ways in which they can be derived, applied, and conceptuatlized is an outcome of their usefulness, but simultaneously a source of frustration when encountering them for the first time. In this article I hope to convey as succinctly as possible, with only as much mathematical flourish as necessary, a core understanding of Green's functions which may save a new physics grad student precious time and energy. Let us begin.

\subsection{Motivation}
Before we develop the mathematical techniques for actually \textit{solving} for Green's functions, lets take a step back and consider why they are so useful. Suppose we have a physical system whose behavior can be modelled by some known differential equation. As is typical in physics, these equations are often written with the LHS (Left Hand Side) containing terms \textit{built in} to the system itself and the RHS (Right Hand Side) representing some \textit{external} force/source/sink/etc. Consider a few examples you have undoubtedly seen before, and which we will cover in detail later:
%
\begin{align}
    m\ddot x(t) + \gamma \dot x(t) + kx(t) &= F_{ext}(t) \label{eq:SHO} \\
    \nabla^2 \phi(\vec r, t) - \frac{1}{c^2}\frac{\partial^2 \phi(\vec r, t)}{\partial t^2} &= -4\pi f(\vec r, t) \label{eq:WAVE} \\
    \frac{\partial u}{\partial t} - \alpha \nabla^2 u &= Q(\vec r, t) \label{eq:HEAT}
\end{align}

In these familiar equations, one can intuitively think of the the RHS terms as some sort of external perturbation and the LHS as representative of the systems instantaneous dynamical response to this perturbation. In the case of the damped and driven harmonic oscillator \eqref{eq:SHO}, $F_{ext}(t)$ might be the force generated by some machine attached by a rod to a spring/mass system. In the wave equation \eqref{eq:WAVE}, $f(\vec r,t)$ would represent the electric charge distribution of electrodynamics. In the heat equation \eqref{eq:HEAT}, $Q(\vec r, t)$ represents heat flux in/out of the system (again via some sort of machine or other means).

Now, if we suppose the LHS of these equations encode the unchangeable, fundamental character of how a particular system responds to external perturbations, we might assume there could be a more direct way of relating the final solution we are after $(x(t), \phi(\vec r,t),u(\vec r,t))$ to the external perturbation rather than going through the machinery of solving the differential equation for each unique form of the perturbation term that we encounter. This is where the Green's function comes in. A Green's function (G) is an \textbf{integral kernel} which can be used to solve an \textbf{inhomogeneous differential equation} with \textbf{specified boundary conditions}. In other words, the solution to our three examples may be written:

\begin{align}
    x(t) &= \int_0^{\infty} G(t,t') F_{ext}(t') dt' \\
    \phi(\vec r,t) &= \int_V \int_0^{\infty} G(\vec r, t; \vec r', t') f(\vec r', t') d\vec r' dt' \\
    u(\vec r,t) &= \int_V \int_0^{\infty} G(\vec r, t; \vec r', t') Q(\vec r', t') d\vec r' dt'
\end{align}

\section{Background}
\subsection{Generalized Functions}
\subsection{Dirac Delta Function}
\subsection{Heaviside Step Function}

\section{A Discrete Analogue}

Suppose for the sake of a computer simulation the trajectory of a particle in 1 dimension is defined as a sequence of $N$ real numbers separated by a time step $\Delta h$. Thus the total time of the simulation is $\left( N-1 \right)\Delta h$ and the trajectory can be represented as a vector:

\begin{align}
\vec x = \colvec{5}{x(t=0)}{x(t=\Delta h)}{x(t=2\Delta h)}{\vdots}{x(t=\left( N-1 \right) \Delta h)} \equiv \colvec{5}{x_1}{x_2}{x_3}{\vdots}{x_N} \in \mathbb{R}^N
\end{align}

For this particular simulation (the particulars of the system being simulated are not important) the time evolution of the trajectory is governed by a matrix equation:

\begin{align}
    \hat L \vec x = \vec f
\end{align}

where $\hat L$ is a nonsingular (invertible) matrix  and $\vec f$ is an $N \times 1$ vector of constant elements. Though we are working within a discrete domain rather than a continuous one, this situation closely resembles what is found in equations \eqref{eq:SHO}, \eqref{eq:WAVE}, and \eqref{eq:HEAT}. In terms of the indexed elements of the matrices and vectors:

\begin{align}
    \sum\limits_{i=1}^N \hat L_{ij} x_j = f_i
\end{align}

So far this is a simple matrix equation, but by analogy with the earlier discussion we can begin to think of $\vec f$ as an external perturbation of the trajectory and $\hat L$ as description of how the system \textit{encodes} this external perturbation onto the trajectory of the particle. Because $\hat L$ is invertible, we can write:

\begin{align}
    x_i = \sum\limits_{i=1}^N \hat L_{ij}^{-1} f_j
\end{align}

All the elements of $\hat L$ and $\vec f$ are known. It follows that the trajectory $\vec x$ is uniquely and completely determined by $\hat L, \vec f$ and $x_1$ (an initial condition). Based on physical consideration we can deduce certain properties of $\hat L^{-1}$ which will prove to be useful.

\subsection{Causality}

The matrix element $L_{ij}^{-1}$ represents the degree to which the trajectory $\vec x$ at time $i$ ($x_i$)  responds to a unit impulse at time $j$.

\subsection{Translational Invariance}

\section{Differential Equations}

\section{Examples}
\subsection{Electrostatics}
\subsection{Driven Oscillator}
\begin{align}
    m \ddot x(t) + kx(t) &= F_{ext}(t)
\end{align}


\subsection{Damped, Driven  Oscillator}

Consider the system
\begin{align}
    m \ddot x(t) + \gamma \dot x(t) + kx(t) &= F_{ext}(t) \label{eq:DDHO}
\end{align}
subject to the boundary conditions

\begin{align}
    x(t < 0) &= 0 \\
    x(t=0) &= x_0 \label{eq:X0}\\
    \dot x(t = 0) &= v_0 \label{eq:V0}
\end{align}

Our goal then is to solve the following inhomogenous ordinary differential equation:
\begin{align}
    m \ddot G(t) + \gamma \dot G(t) + kG(t) &= \delta(t) \label{eq:DDHOG}
\end{align}


In this case it turns out to be easier to work with the Fourier representation:

\begin{align}
    G(t) &= \frac{1}{2\pi} \int_{-\infty}^{\infty} g(\omega) e^{i\omega t} d\omega \label{eq:DDHOGF} \\
    \delta(t) &= \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{i\omega t} d\omega \label{eq:DF}
\end{align}

By plugging \eqref{eq:DDHOGF} and \eqref{eq:DF} into \eqref{eq:DDHOG}, applying deriatives are rearranging terms:

\begin{align}
    \int_{-\infty}^{\infty} \left[ \left\{ -m\omega^2 + i\omega \gamma + k \right\}g(\omega) - 1 \right] e^{i\omega t} d\omega = 0
\end{align}

Since the basis functions $e^{i\omega t}$ of the fourier representation form an orthonormal basis, it follows that

\begin{align}
    \forall \omega, \ \ \ \left\{ -m\omega^2 + i\omega \gamma + k \right\}g(\omega) - 1 = 0 \\
    \Rightarrow G(t) = \frac{1}{2\pi} \int_{-\infty}^{\infty} \frac{e^{i\omega t}}{-m\omega^2 + i\omega \gamma + k} dw
\end{align}

In preparation for solving the integral via residue calculus, we factor the denominator

\begin{align}
    G(t) &= \frac{1}{2\pi}\oint_C \frac{e^{i\omega t}}{\left( \omega-\Omega_+ \right) \left( \omega - \Omega_- \right)} d\omega
\end{align}

where $\Omega_{\pm} = i\frac{\gamma}{2m} \mp \sqrt{\frac{k}{m}-\frac{\gamma^2}{4m^2}}$ and $C$ is the UHP infinite semi-circle.  Both roots are in the upper half plane no matter the relation between $k$ and $\gamma$, so the residues of both poles must be evaluated:

\begin{align}
    G(t) &= i \left[ \frac{e^{i\Omega_+ t} - e^{i \Omega_- t}}{\Omega_- - \Omega_+} \right] \\
    &= \frac{e^{\frac{-\gamma}{2m} t}}{\sqrt{\frac{k}{m}-\frac{\gamma^2}{4m^2}}} \frac{1}{2i} \left( e^{i \sqrt{\frac{k}{m}-\frac{\gamma^2}{4m^2}} t} - e^{-i \sqrt{\frac{k}{m}-\frac{\gamma^2}{4m^2}} t} \right) \\
    &\equiv \frac{e^{-bt}}{\omega_1}\sin{\omega_1 t}
\end{align}

where $b \equiv \frac{\gamma}{2m}$ and $\omega_1 \equiv \sqrt{\frac{k}{m}-\frac{\gamma^2}{4m^2}}$. By taking $t \rightarrow t-t_0$ and imposiing  the causality condition $G(t<0)=0$ we have our final solution:


\begin{align}
    \highlight{G(t-t_0) = \theta(t-t_0) \frac{e^{-b\left( t-t_0 \right)}}{\omega_1}\sin\left[ \omega_1 \left( t-t_0 \right) \right]}
\end{align}

In order to account for boundary conditions \eqref{eq:X0} and \eqref{eq:V0}, we must write the full solution $x(t)$ as a combination of complimentary (transient) and particular (steady state) solutions $x(t) = x_p(t) + x_c(t)$

\begin{align}
    x_p(t) &= \int_{0}^{t} \frac{e^{-b\left( t-t_0 \right)}}{\omega_1}\sin\left[ \omega_1 \left( t-t_0 \right) \right] f(t_0) dt_0 \\
    x_c(t) &=\theta(t) \  e^{-bt}\left[ \frac{x_0\left( \omega_1+b \right)+v_0  }{2\omega_1}e^{\omega_1 t} + \frac{x_0\left( \omega_1-b \right)-v_0  }{2\omega_1}e^{-\omega_1 t} \right]
\end{align}

where the the action of $\theta(t-t_0)$ has transformed the limits of integration. $x_c(t)$ is merely the familiar (though perhaps no written in precisely this way) solution to the homogeneous equivalent of \eqref{eq:DDHO}, with $\theta(t)$ included to account for our continued assumption that $x(t<0) = 0$.



\subsection{Helmholtz Equation}

\begin{align}
\left( \nabla^2+k^2 \right)\phi(\vec r) = -4\pi f(\vec r) \\
\left( \nabla^2+k^2 \right)G_k(\vec r) = -4\pi \delta(\vec r)
\end{align}

Here the subscript $k$ in $G_k(\vec r)$ indicates the depdence of the Green's function on the particular value of k. This will aid us in deriving the Green's function of the wave equation later. If we assume there are no boundary surfaces, the Green's function can only depend on $r \equiv |\vec r - \vec r'|$ and we can exploit the simplicity of the spherically symmetric Laplacian:

\begin{align}
    \frac{1}{r} \frac{d^2}{dr^2} \left( rG(r) \right) + k^2 G(r) = -4\pi \delta(r)
\end{align}





\subsection{Wave Equation}
\subsection{Free Particle (QM)}

\section{Distribution Theory \& Fundamental Solution}
\section{Resources}

\end{document}

